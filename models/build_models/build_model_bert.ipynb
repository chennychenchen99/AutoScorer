in{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CSE115_build_model_bert.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBloMAIT0XOF"
      },
      "source": [
        "!pip install -q tensorflow-text\n",
        "!pip install -q tf-models-official"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9LhGozg01Is"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUC0Vrc71xDy"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Input, Bidirectional, LSTM\n",
        "from tensorflow.keras import callbacks\n",
        "from tensorflow.keras.models import load_model, Model\n",
        "from tensorflow.keras import optimizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import cohen_kappa_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLMcb5Bs0RzL"
      },
      "source": [
        "# Hyperparameters\n",
        "\n",
        "seq_length = 350\n",
        "learning_rate = 5e-5\n",
        "optimizer = optimizers.Adam(learning_rate)\n",
        "batch_size = 32\n",
        "epochs = 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPnWSvyF0Vni"
      },
      "source": [
        "# Additional hyperparameters for bigger model\n",
        "\n",
        "LSTM1_units = 200\n",
        "LSTM2_units = 64\n",
        "dropout = 0.10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nt3Ngpp-3bql"
      },
      "source": [
        "train_df = pd.read_excel('/content/gdrive/MyDrive/CSE115A_supplement_folder/train_data.xlsx')\n",
        "\n",
        "# Create a validation set using 10% of training data\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.1, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5FxLhEO34LC"
      },
      "source": [
        "X_train = np.asarray(train_df['essay'].tolist())\n",
        "X_val = np.asarray(val_df['essay'].tolist())\n",
        "\n",
        "y_train = np.asarray(train_df['domain1_score'].tolist())\n",
        "y_val = np.asarray(val_df['domain1_score'].tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VU7dnC7t48fG"
      },
      "source": [
        "tfhub_handle_encoder = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1'\n",
        "tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n",
        "\n",
        "tfhub_handle_encoder_small = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1'\n",
        "tfhub_handle_preprocess_small = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n",
        "\n",
        "def build_model(sequence_len):\n",
        "    # Building the model using the bigger version of BERT\n",
        "    preprocessor = hub.load(tfhub_handle_preprocess)\n",
        "\n",
        "    text_input = [tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')]\n",
        "    tokenize = hub.KerasLayer(preprocessor.tokenize)\n",
        "    tokenized_inputs = [tokenize(segment) for segment in text_input]\n",
        "\n",
        "    bert_pack_inputs = hub.KerasLayer(preprocessor.bert_pack_inputs, \n",
        "                                      arguments=dict(seq_length=sequence_len))\n",
        "    encoder_inputs = bert_pack_inputs(tokenized_inputs)\n",
        "    encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
        "    outputs = encoder(encoder_inputs)\n",
        "\n",
        "    x = outputs['sequence_output']\n",
        "    x = Bidirectional(LSTM(LSTM1_units, recurrent_dropout=0.35, return_sequences=True))(x)\n",
        "    x = Bidirectional(LSTM(LSTM2_units, recurrent_dropout=0.15))(x)\n",
        "    x = tf.keras.layers.Dropout(dropout)(x)\n",
        "    out = tf.keras.layers.Dense(1, activation='relu', name='out')(x)\n",
        "\n",
        "    return tf.keras.Model(text_input, out)\n",
        "\n",
        "\n",
        "def build_model_small(sequence_len):\n",
        "    # Building the model using a smaller version of BERT\n",
        "    preprocessor = hub.load(tfhub_handle_preprocess_small)\n",
        "\n",
        "    text_input = [tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')]\n",
        "    tokenize = hub.KerasLayer(preprocessor.tokenize)\n",
        "    tokenized_inputs = [tokenize(segment) for segment in text_input]\n",
        "\n",
        "    bert_pack_inputs = hub.KerasLayer(preprocessor.bert_pack_inputs, \n",
        "                                      arguments=dict(seq_length=sequence_len))\n",
        "    encoder_inputs = bert_pack_inputs(tokenized_inputs)\n",
        "    encoder = hub.KerasLayer(tfhub_handle_encoder_small, trainable=True, \n",
        "                             name='BERT_encoder')\n",
        "    outputs = encoder(encoder_inputs)\n",
        "\n",
        "    x = outputs['sequence_output']\n",
        "    out = tf.keras.layers.Dense(1, activation='relu', name='out')(x)\n",
        "\n",
        "    return tf.keras.Model(text_input, out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzLmxS9KsAOt"
      },
      "source": [
        "callbacks_list = [\n",
        "    # Save the model when it achieves the lowest loss on validation set\n",
        "    callbacks.ModelCheckpoint(\n",
        "        filepath='/content/gdrive/MyDrive/CSE115A_supplement_folder/model_bert_small',\n",
        "        monitor='val_loss',\n",
        "        mode='min',\n",
        "        save_best_only=True,\n",
        "    )\n",
        "]\n",
        "\n",
        "model = build_model_small(seq_length)\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='mean_squared_error',\n",
        "              metrics=['mae'])\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(X_train, y_train, \n",
        "                    validation_data=(X_val, y_val),\n",
        "                    epochs=epochs, \n",
        "                    batch_size=batch_size, \n",
        "                    callbacks=callbacks_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xIiAGVy-GjB"
      },
      "source": [
        "# Load the best model that was saved during training and calculate quadratic weighted kappa score\n",
        "loaded_model = tf.saved_model.load('/content/gdrive/MyDrive/CSE115A_supplement_folder/model_bert_small')\n",
        "\n",
        "prediction_tensors = tf.nn.relu(loaded_model(tf.constant(X_val)))\n",
        "\n",
        "preds = []\n",
        "for values in prediction_tensors:\n",
        "    preds.append(values.numpy()[0])\n",
        "\n",
        "preds = np.asarray(preds)\n",
        "preds = np.around(preds)\n",
        "\n",
        "kappa_score = cohen_kappa_score(preds, y_val, weights='quadratic')\n",
        "print(f\"Quadratic Kappa Score on Validation Set: {kappa_score}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
